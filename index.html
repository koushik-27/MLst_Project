<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automatic Music Tagging with CRNNs</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Automatic Music Tagging with CRNNs</h1>
        <h2>Prof. Mark Cartwright</h2>
        <p>CS698: Machine Listening (Project)</p>
    </header>
    <main>
        <section id="about">
            <h2>About the Project</h2>
            <p>In the evolving field of Music Information Retrieval (MIR), the task of automatically tagging music with relevant moods and themes is not just a convenience but a necessity, given the vast expanse of digital music available today. The project at hand addresses this challenge by implementing a Convolutional Recurrent Neural Network (CRNN) to analyze and tag music tracks, focusing on mood and theme recognition. This approach is particularly innovative in its application to low-quality data, making it a versatile tool in real-world scenarios where high-fidelity recordings may not always be available.</p>
            <p>Utilizing the MTG Jamendo Dataset, which is replete with mood and theme annotations, the project leverages Mel spectrograms extracted from audio tracks as input for the CRNN model. The CRNN architecture is uniquely suited for this task, combining the spatial feature recognition capabilities of CNNs with the sequential data processing power of RNNs. This allows for a robust analysis of both the textural and temporal aspects of music.</p>
            <p>The construction and testing of the model involved generating Mel spectrograms of size 128x1024 from the music tracks in the dataset. These detailed feature representations are then processed through a series of convolutional layers designed to extract salient features, followed by recurrent layers that capture the temporal dynamics of the audio signals. The final mood and theme classification is accomplished via dense layers, culminating in a system capable of understanding and tagging a diverse range of musical expressions.</p>
            <p>The performance of the model, as illustrated by the provided graphs, shows a consistently high accuracy and Area Under the Curve (AUC) on training data, with validation results following closely. This indicates not only the model's ability to learn from the dataset but also its potential to generalize well to unseen data. Despite the inherent challenges of working with low-quality audio, the system demonstrates remarkable efficacy in mood and theme recognition, promising a significant contribution to the automation of music tagging.</p>
        </section>
        <section id="visualization">
            <h2>Model Architecture</h2>
            <figure>
                <img src="images/crnn_model.h5.png" alt="Model Architecture" width="400">
                <figcaption>Figure 2: CRNN Model Architecture</figcaption>
            </figure>
            <h2>Model Performance</h2>
            <figure>
                <img src="images/model_performance.png" alt="Model Performance Graphs" width="600">
                <figcaption>Figure 1: Training and validation curves showing the Model Accuracy and Model AUC over 30 epochs. The left graph displays the accuracy, with the training accuracy in blue and validation accuracy in orange. The right graph shows the AUC, indicating the model's predictive quality, with higher values representing better performance.</figcaption>
            </figure>
        </section>
        <section id="team">
            <h2>Project Team</h2>
            <ul>
                <li>Atharva Dumbre</li>
                <li>Naga Kousick Reddy Voggu</li>
                <!-- Add more team members as needed -->
            </ul>
        </section>
        <section id="contact">
            <h2>Contact</h2>
            </p><a href="mailto:add@njit.edu">add@njit.edu</a></p>
            <p><a href="mailto:nv344@njit.edu">nv344@njit.edu</a></p>
        </section>
    </main>
    <footer>
        <p>&copy; 2023 Automatic Music Tagging Project</p>
    </footer>
</body>
</html>
