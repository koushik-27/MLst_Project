{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9dafea-56b4-4221-aa0c-3b2c7f88ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20e85a4-d972-46d7-9896-265b20acbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c950a3d2-8acd-4578-b6db-2ffb2848cdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 18486 tracks, 4506 albums, 1533 artists\n"
     ]
    }
   ],
   "source": [
    "from mtg_jamendo_dataset.scripts import commons\n",
    "\n",
    "input_file = 'C:/Projects/Music_Tagging/mtg_jamendo_dataset/data/autotagging_moodtheme.tsv'\n",
    "tracks, tags, extra = commons.read_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a87e46a-7621-4083-ba91-6a74cf047ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48/948.mp3</td>\n",
       "      <td>{background}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50/950.mp3</td>\n",
       "      <td>{background}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51/951.mp3</td>\n",
       "      <td>{background}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65/2165.mp3</td>\n",
       "      <td>{film}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63/2263.mp3</td>\n",
       "      <td>{melancholic}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18481</th>\n",
       "      <td>56/1422056.mp3</td>\n",
       "      <td>{advertising, dramatic, epic, movie}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18482</th>\n",
       "      <td>57/1422057.mp3</td>\n",
       "      <td>{advertising, dramatic, epic, movie}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18483</th>\n",
       "      <td>58/1422058.mp3</td>\n",
       "      <td>{dramatic, epic, movie}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18484</th>\n",
       "      <td>59/1422059.mp3</td>\n",
       "      <td>{advertising, dramatic, epic, movie}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18485</th>\n",
       "      <td>60/1422060.mp3</td>\n",
       "      <td>{advertising, dramatic, epic, movie}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                paths                                  tags\n",
       "0          48/948.mp3                          {background}\n",
       "1          50/950.mp3                          {background}\n",
       "2          51/951.mp3                          {background}\n",
       "3         65/2165.mp3                                {film}\n",
       "4         63/2263.mp3                         {melancholic}\n",
       "...               ...                                   ...\n",
       "18481  56/1422056.mp3  {advertising, dramatic, epic, movie}\n",
       "18482  57/1422057.mp3  {advertising, dramatic, epic, movie}\n",
       "18483  58/1422058.mp3               {dramatic, epic, movie}\n",
       "18484  59/1422059.mp3  {advertising, dramatic, epic, movie}\n",
       "18485  60/1422060.mp3  {advertising, dramatic, epic, movie}\n",
       "\n",
       "[18486 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "tags = []\n",
    "for song_id, song_data in tracks.items():\n",
    "    paths.append(song_data['path'])\n",
    "    tags.append(song_data['mood/theme'])\n",
    "\n",
    "df = pd.DataFrame({'paths': paths, 'tags': tags})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d73752c-5c3e-429b-8185-cd68015ba358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calm', 'background', 'adventure', 'corporate', 'nature', 'movie', 'soundscape', 'fun', 'groovy', 'documentary', 'christmas', 'inspiring', 'summer', 'uplifting', 'fast', 'mellow', 'upbeat', 'funny', 'party', 'dramatic', 'deep', 'slow', 'energetic', 'powerful', 'retro', 'advertising', 'epic', 'trailer', 'meditative', 'hopeful', 'holiday', 'sport', 'children', 'cool', 'commercial', 'sad', 'motivational', 'ambiental', 'soft', 'sexy', 'film', 'positive', 'ballad', 'space', 'emotional', 'drama', 'relaxing', 'romantic', 'love', 'melancholic', 'travel', 'dream', 'horror', 'action', 'heavy', 'melodic', 'happy', 'game', 'dark']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_13288\\3162749104.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['tags'] = df['tags'].str.replace('{', '').str.replace('}', '').str.split(',')\n"
     ]
    }
   ],
   "source": [
    "df['tags'] = df['tags'].astype(str)\n",
    "\n",
    "# Remove curly braces, split the tags, and strip whitespaces and quotes\n",
    "df['tags'] = df['tags'].str.replace('{', '').str.replace('}', '').str.split(',')\n",
    "df['tags'] = df['tags'].apply(lambda tags: [tag.strip().strip(\"'\").strip('\"').strip() for tag in tags])\n",
    "\n",
    "# Get unique tags\n",
    "unique_tags = set()\n",
    "for tags in df['tags']:\n",
    "    unique_tags.update(tags)\n",
    "\n",
    "# Convert the set of unique tags to a list\n",
    "unique_classes = list(unique_tags)\n",
    "\n",
    "# Print or use the unique tags\n",
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca5c88c-aff8-403a-a98a-8b8133e6256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_table(tracks):\n",
    "    paths = []\n",
    "    tags = []\n",
    "    for song_id, song_data in tracks.items():\n",
    "        paths.append(song_data['path'])\n",
    "        tags.append(song_data['mood/theme'])\n",
    "\n",
    "    df = pd.DataFrame({'paths': paths, 'tags': tags})\n",
    "    df['tags'] = df['tags'].astype(str)\n",
    "    df['tags'] = df['tags'].str.replace('{', '').str.replace('}', '')\n",
    "    df['paths'] = df['paths'].str.replace('/', '_')\n",
    "    df['paths'] = 'C:/Projects/Music_Tagging/large_mel_spec/' + df['paths']\n",
    "    df['paths'] = df['paths'].str.replace('.mp3', '.low.npy')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295f4d43-b8b5-4232-8a6f-10885c0a5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_13288\\1584220965.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['tags'] = df['tags'].str.replace('{', '').str.replace('}', '')\n",
      "C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_13288\\1584220965.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['paths'] = df['paths'].str.replace('.mp3', '.low.npy')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/48_94...</td>\n",
       "      <td>'background'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/50_95...</td>\n",
       "      <td>'background'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/51_95...</td>\n",
       "      <td>'background'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/65_21...</td>\n",
       "      <td>'film'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/63_22...</td>\n",
       "      <td>'melancholic'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/46_33...</td>\n",
       "      <td>'calm', 'melodic'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/47_33...</td>\n",
       "      <td>'calm', 'melodic'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/48_33...</td>\n",
       "      <td>'calm', 'melodic'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/49_33...</td>\n",
       "      <td>'calm', 'melodic'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/50_33...</td>\n",
       "      <td>'calm', 'melodic'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paths               tags\n",
       "0  C:/Projects/Music_Tagging/large_mel_spec/48_94...       'background'\n",
       "1  C:/Projects/Music_Tagging/large_mel_spec/50_95...       'background'\n",
       "2  C:/Projects/Music_Tagging/large_mel_spec/51_95...       'background'\n",
       "3  C:/Projects/Music_Tagging/large_mel_spec/65_21...             'film'\n",
       "4  C:/Projects/Music_Tagging/large_mel_spec/63_22...      'melancholic'\n",
       "5  C:/Projects/Music_Tagging/large_mel_spec/46_33...  'calm', 'melodic'\n",
       "6  C:/Projects/Music_Tagging/large_mel_spec/47_33...  'calm', 'melodic'\n",
       "7  C:/Projects/Music_Tagging/large_mel_spec/48_33...  'calm', 'melodic'\n",
       "8  C:/Projects/Music_Tagging/large_mel_spec/49_33...  'calm', 'melodic'\n",
       "9  C:/Projects/Music_Tagging/large_mel_spec/50_33...  'calm', 'melodic'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_table(tracks)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "881295e1-ed68-44d2-b515-f10e2f357c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>advertising</th>\n",
       "      <th>ambiental</th>\n",
       "      <th>background</th>\n",
       "      <th>ballad</th>\n",
       "      <th>calm</th>\n",
       "      <th>children</th>\n",
       "      <th>christmas</th>\n",
       "      <th>...</th>\n",
       "      <th>slow</th>\n",
       "      <th>soft</th>\n",
       "      <th>soundscape</th>\n",
       "      <th>space</th>\n",
       "      <th>sport</th>\n",
       "      <th>summer</th>\n",
       "      <th>trailer</th>\n",
       "      <th>travel</th>\n",
       "      <th>upbeat</th>\n",
       "      <th>uplifting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/48_94...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/50_95...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/51_95...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/65_21...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Projects/Music_Tagging/large_mel_spec/63_22...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paths  action  adventure  \\\n",
       "0  C:/Projects/Music_Tagging/large_mel_spec/48_94...       0          0   \n",
       "1  C:/Projects/Music_Tagging/large_mel_spec/50_95...       0          0   \n",
       "2  C:/Projects/Music_Tagging/large_mel_spec/51_95...       0          0   \n",
       "3  C:/Projects/Music_Tagging/large_mel_spec/65_21...       0          0   \n",
       "4  C:/Projects/Music_Tagging/large_mel_spec/63_22...       0          0   \n",
       "\n",
       "   advertising  ambiental  background  ballad  calm  children  christmas  ...  \\\n",
       "0            0          0           1       0     0         0          0  ...   \n",
       "1            0          0           1       0     0         0          0  ...   \n",
       "2            0          0           1       0     0         0          0  ...   \n",
       "3            0          0           0       0     0         0          0  ...   \n",
       "4            0          0           0       0     0         0          0  ...   \n",
       "\n",
       "   slow  soft  soundscape  space  sport  summer  trailer  travel  upbeat  \\\n",
       "0     0     0           0      0      0       0        0       0       0   \n",
       "1     0     0           0      0      0       0        0       0       0   \n",
       "2     0     0           0      0      0       0        0       0       0   \n",
       "3     0     0           0      0      0       0        0       0       0   \n",
       "4     0     0           0      0      0       0        0       0       0   \n",
       "\n",
       "   uplifting  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'] = df['tags'].str.replace(\"'\", \"\").str.split(', ')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Transform the 'tags' column into binary columns\n",
    "binary_labels = mlb.fit_transform(df['tags'])\n",
    "\n",
    "# Create a new DataFrame with binary labels\n",
    "df_labels = pd.DataFrame(binary_labels, columns=mlb.classes_)\n",
    "\n",
    "# Concatenate the new labels DataFrame with the original DataFrame\n",
    "df = pd.concat([df, df_labels], axis=1)\n",
    "\n",
    "# Drop the original 'tags' column if you no longer need it\n",
    "df.drop('tags', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e797127c-1d13-451b-ad7b-187a369f3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class SpectrogramDataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, batch_size, mel_shape=(128, 1024, 1), spectrogram_dir='path_to_spectrograms'):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.mel_shape = mel_shape\n",
    "        self.spectrogram_dir = spectrogram_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = (index + 1) * self.batch_size\n",
    "        batch_df = self.dataframe.iloc[start_idx:end_idx]\n",
    "        \n",
    "        X = np.zeros((len(batch_df), *self.mel_shape))\n",
    "        y = batch_df.iloc[:, 1:].values  # Assuming binary class labels are in columns 1 onwards\n",
    "\n",
    "        for i, spectrogram_path in enumerate(batch_df['paths']):\n",
    "            spectrogram = np.load(os.path.join(self.spectrogram_dir, spectrogram_path))\n",
    "            X[i] = spectrogram.reshape(self.mel_shape)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52efb519-1e1f-4a8a-8353-41396574a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "mel_shape = (128, 1024, 1)  # Modify this according to your mel spectrogram shape\n",
    "spectrogram_dir = 'C:/Projects/Music_Tagging/processed_data/'\n",
    "\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.3, random_state=17)  # Allocating 30% for combined validation and test sets\n",
    "\n",
    "# Further split the validation/test set into separate validation and test sets\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=17)  # Splitting half for validation and half for test\n",
    "\n",
    "# Create data generators for training, validation, and test sets\n",
    "train_generator = SpectrogramDataGenerator(train_df, batch_size=batch_size, mel_shape=mel_shape, spectrogram_dir=spectrogram_dir)\n",
    "val_generator = SpectrogramDataGenerator(val_df, batch_size=batch_size, mel_shape=mel_shape, spectrogram_dir=spectrogram_dir)\n",
    "test_generator = SpectrogramDataGenerator(test_df, batch_size=batch_size, mel_shape=mel_shape, spectrogram_dir=spectrogram_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e6f5bd-b043-4356-b3cd-4745d961f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.0000001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a6f7a8-c1c7-4c71-b2ce-ca6c7d651bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 1022, 32)     320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 511, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 509, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 254, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 252, 64)       36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 126, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 124, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 62, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 47616)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6094976   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 59)                7611      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,232,187\n",
      "Trainable params: 6,232,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n",
      "405/405 [==============================] - 64s 143ms/step - loss: 0.1555 - accuracy: 0.0596 - auc: 0.6600 - auc_1: 0.0548 - f1_score: 0.0171 - val_loss: 0.1288 - val_accuracy: 0.0887 - val_auc: 0.7015 - val_auc_1: 0.0770 - val_f1_score: 0.0175 - lr: 0.0010\n",
      "Epoch 2/250\n",
      "405/405 [==============================] - 56s 139ms/step - loss: 0.1254 - accuracy: 0.0784 - auc: 0.7077 - auc_1: 0.0769 - f1_score: 0.0241 - val_loss: 0.1263 - val_accuracy: 0.0772 - val_auc: 0.7159 - val_auc_1: 0.0830 - val_f1_score: 0.0187 - lr: 0.0010\n",
      "Epoch 3/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1240 - accuracy: 0.0820 - auc: 0.7232 - auc_1: 0.0826 - f1_score: 0.0287 - val_loss: 0.1260 - val_accuracy: 0.0851 - val_auc: 0.7297 - val_auc_1: 0.0877 - val_f1_score: 0.0239 - lr: 0.0010\n",
      "Epoch 4/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1221 - accuracy: 0.0951 - auc: 0.7418 - auc_1: 0.0902 - f1_score: 0.0343 - val_loss: 0.1238 - val_accuracy: 0.0912 - val_auc: 0.7479 - val_auc_1: 0.1000 - val_f1_score: 0.0341 - lr: 0.0010\n",
      "Epoch 5/250\n",
      "405/405 [==============================] - 57s 141ms/step - loss: 0.1205 - accuracy: 0.0995 - auc: 0.7553 - auc_1: 0.0998 - f1_score: 0.0418 - val_loss: 0.1235 - val_accuracy: 0.1060 - val_auc: 0.7451 - val_auc_1: 0.1001 - val_f1_score: 0.0297 - lr: 0.0010\n",
      "Epoch 6/250\n",
      "405/405 [==============================] - 57s 141ms/step - loss: 0.1196 - accuracy: 0.1063 - auc: 0.7635 - auc_1: 0.1034 - f1_score: 0.0465 - val_loss: 0.1223 - val_accuracy: 0.1096 - val_auc: 0.7599 - val_auc_1: 0.1081 - val_f1_score: 0.0400 - lr: 0.0010\n",
      "Epoch 7/250\n",
      "405/405 [==============================] - 57s 141ms/step - loss: 0.1185 - accuracy: 0.1158 - auc: 0.7714 - auc_1: 0.1131 - f1_score: 0.0557 - val_loss: 0.1225 - val_accuracy: 0.1049 - val_auc: 0.7577 - val_auc_1: 0.1081 - val_f1_score: 0.0478 - lr: 0.0010\n",
      "Epoch 8/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1172 - accuracy: 0.1199 - auc: 0.7808 - auc_1: 0.1219 - f1_score: 0.0629 - val_loss: 0.1227 - val_accuracy: 0.1114 - val_auc: 0.7608 - val_auc_1: 0.1157 - val_f1_score: 0.0417 - lr: 0.0010\n",
      "Epoch 9/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1156 - accuracy: 0.1232 - auc: 0.7914 - auc_1: 0.1327 - f1_score: 0.0697 - val_loss: 0.1225 - val_accuracy: 0.1093 - val_auc: 0.7616 - val_auc_1: 0.1157 - val_f1_score: 0.0502 - lr: 0.0010\n",
      "Epoch 10/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1148 - accuracy: 0.1324 - auc: 0.7965 - auc_1: 0.1396 - f1_score: 0.0809 - val_loss: 0.1219 - val_accuracy: 0.1006 - val_auc: 0.7611 - val_auc_1: 0.1139 - val_f1_score: 0.0535 - lr: 0.0010\n",
      "Epoch 11/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1130 - accuracy: 0.1400 - auc: 0.8079 - auc_1: 0.1519 - f1_score: 0.0882 - val_loss: 0.1222 - val_accuracy: 0.1075 - val_auc: 0.7623 - val_auc_1: 0.1108 - val_f1_score: 0.0576 - lr: 0.0010\n",
      "Epoch 12/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1116 - accuracy: 0.1505 - auc: 0.8152 - auc_1: 0.1651 - f1_score: 0.1002 - val_loss: 0.1232 - val_accuracy: 0.1078 - val_auc: 0.7592 - val_auc_1: 0.1067 - val_f1_score: 0.0538 - lr: 0.0010\n",
      "Epoch 13/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.1098 - accuracy: 0.1611 - auc: 0.8252 - auc_1: 0.1813 - f1_score: 0.1163 - val_loss: 0.1246 - val_accuracy: 0.1107 - val_auc: 0.7549 - val_auc_1: 0.1194 - val_f1_score: 0.0577 - lr: 0.0010\n",
      "Epoch 14/250\n",
      "405/405 [==============================] - 57s 139ms/step - loss: 0.1074 - accuracy: 0.1717 - auc: 0.8354 - auc_1: 0.2041 - f1_score: 0.1309 - val_loss: 0.1286 - val_accuracy: 0.0995 - val_auc: 0.7490 - val_auc_1: 0.1060 - val_f1_score: 0.0672 - lr: 0.0010\n",
      "Epoch 15/250\n",
      "405/405 [==============================] - 56s 139ms/step - loss: 0.1050 - accuracy: 0.1847 - auc: 0.8479 - auc_1: 0.2214 - f1_score: 0.1439 - val_loss: 0.1284 - val_accuracy: 0.0941 - val_auc: 0.7463 - val_auc_1: 0.1094 - val_f1_score: 0.0617 - lr: 0.0010\n",
      "Epoch 16/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.0941 - accuracy: 0.2546 - auc: 0.8885 - auc_1: 0.3312 - f1_score: 0.2199 - val_loss: 0.1301 - val_accuracy: 0.1064 - val_auc: 0.7512 - val_auc_1: 0.1148 - val_f1_score: 0.0754 - lr: 2.0000e-04\n",
      "Epoch 17/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.0904 - accuracy: 0.2784 - auc: 0.8989 - auc_1: 0.3692 - f1_score: 0.2485 - val_loss: 0.1327 - val_accuracy: 0.1039 - val_auc: 0.7445 - val_auc_1: 0.1129 - val_f1_score: 0.0783 - lr: 2.0000e-04\n",
      "Epoch 18/250\n",
      "405/405 [==============================] - 57s 140ms/step - loss: 0.0879 - accuracy: 0.2949 - auc: 0.9061 - auc_1: 0.3933 - f1_score: 0.2701 - val_loss: 0.1359 - val_accuracy: 0.1053 - val_auc: 0.7343 - val_auc_1: 0.1087 - val_f1_score: 0.0816 - lr: 2.0000e-04\n",
      "Epoch 19/250\n",
      "405/405 [==============================] - 57s 141ms/step - loss: 0.0853 - accuracy: 0.3114 - auc: 0.9127 - auc_1: 0.4207 - f1_score: 0.2862 - val_loss: 0.1383 - val_accuracy: 0.0956 - val_auc: 0.7337 - val_auc_1: 0.1077 - val_f1_score: 0.0735 - lr: 2.0000e-04\n",
      "Epoch 20/250\n",
      "405/405 [==============================] - 57s 141ms/step - loss: 0.0827 - accuracy: 0.3291 - auc: 0.9197 - auc_1: 0.4477 - f1_score: 0.3044 - val_loss: 0.1419 - val_accuracy: 0.0984 - val_auc: 0.7281 - val_auc_1: 0.1055 - val_f1_score: 0.0703 - lr: 2.0000e-04\n",
      "87/87 [==============================] - 17s 192ms/step - loss: 0.1201 - accuracy: 0.1031 - auc: 0.7619 - auc_1: 0.1143 - f1_score: 0.0585\n",
      "Validation loss: 0.1201, Validation accuracy: 0.1031\n"
     ]
    }
   ],
   "source": [
    "base_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=mel_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(train_df.columns) - 1, activation='sigmoid')  # Output layer with one node per class\n",
    "])\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "# Compile the model\n",
    "base_model.compile(optimizer=Adam(learning_rate=initial_learning_rate), loss=BinaryCrossentropy(), metrics=['accuracy', tf.keras.metrics.AUC(curve='ROC'),tf.metrics.AUC(curve='PR'),tfa.metrics.F1Score(num_classes=59, average='macro')])\n",
    "# Train the model\n",
    "base_model_history = base_model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[early_stopping,reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, rocauc, prauc, f1macro = base_model.evaluate(test_generator)\n",
    "print(f'Validation loss: {loss:.4f}, Validation accuracy: {accuracy:.4f}')\n",
    "\n",
    "base_model.save(\"base_model.h5\")\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "552dc319-0c42-4ff8-8ba1-2befbad1f2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20251a99660>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and save the history\n",
    "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Similarly, for other metrics like ROC-AUC, PR-AUC, and F1 Score\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('Model ROC-AUC')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['f1_score'])  # Adjust the key based on how it's named in history\n",
    "plt.plot(history.history['val_f1_score'])  # Adjust the key based on how it's named in history\n",
    "plt.title('Model F1 Score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3f1dac-198b-4093-aee5-fd9a652ce267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.1\n",
    "\n",
    "# spectrogram_path = 'C:/Projects/Music_Tagging/processed_data/00_468500.low.npy'\n",
    "# spectrogram = np.load(spectrogram_path)  # Replace with the path to your spectrogram file\n",
    "# spectrogram = np.expand_dims(spectrogram, axis=0)  # Add a batch dimension\n",
    "\n",
    "# predictions = model.predict(spectrogram)\n",
    "\n",
    "# class_indices = np.where(predictions[0] >= threshold)[0]  # Use a threshold to select classes\n",
    "\n",
    "# # Get the class labels corresponding to the selected indices\n",
    "# selected_classes = [unique_classes[i] for i in class_indices]\n",
    "\n",
    "# # Print or use the selected classes\n",
    "# print(\"Selected classes:\", selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "117c0999-bf5a-4b55-bd53-bbf832f88502",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5482d59a-48b5-49fa-89d8-e35e2a117e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Dense, Dropout, ELU, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, num_class=len(train_df.columns) - 1):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # init bn\n",
    "        self.bn_init = BatchNormalization()\n",
    "\n",
    "        # layer 1\n",
    "        self.conv_1 = Conv2D(64, 3, padding='same')\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.mp_1 = MaxPooling2D((2, 4))\n",
    "\n",
    "        # layer 2\n",
    "        self.conv_2 = Conv2D(128, 3, padding='same')\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.mp_2 = MaxPooling2D((2, 4))\n",
    "\n",
    "        # layer 3\n",
    "        self.conv_3 = Conv2D(128, 3, padding='same')\n",
    "        self.bn_3 = BatchNormalization()\n",
    "        self.mp_3 = MaxPooling2D((2, 4))\n",
    "\n",
    "        # # layer 4\n",
    "        self.conv_4 = Conv2D(128, 3, padding='same')\n",
    "        self.bn_4 = BatchNormalization()\n",
    "        self.mp_4 = MaxPooling2D((3, 5))\n",
    "\n",
    "        # # layer 5\n",
    "        # self.conv_5 = Conv2D(64, 3, padding='same')\n",
    "        # self.bn_5 = BatchNormalization()\n",
    "        # self.mp_5 = MaxPooling2D((4, 4))\n",
    "\n",
    "        # classifier\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(num_class, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "\n",
    "    def call(self, x):\n",
    "        # init bn\n",
    "        x = self.bn_init(x)\n",
    "\n",
    "        # layer 1\n",
    "        x = self.mp_1(ELU()(self.bn_1(self.conv_1(x))))\n",
    "\n",
    "        # layer 2\n",
    "        x = self.mp_2(ELU()(self.bn_2(self.conv_2(x))))\n",
    "\n",
    "        # layer 3\n",
    "        x = self.mp_3(ELU()(self.bn_3(self.conv_3(x))))\n",
    "\n",
    "        # # layer 4\n",
    "        x = self.mp_4(ELU()(self.bn_4(self.conv_4(x))))\n",
    "\n",
    "        # # layer 5\n",
    "        # x = self.mp_5(ELU()(self.bn_5(self.conv_5(x))))\n",
    "\n",
    "        # classifier\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense(x)\n",
    "\n",
    "# Instantiate and build the model\n",
    "vgg_model = CNN(num_class=len(train_df.columns) - 1)\n",
    "vgg_model.build((None, 128, 1024, 1))  # Replace with your input shape, e.g., (None, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "119d4b15-8005-44a5-b540-e9d21fe6675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_4 (Batc  multiple                 4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           multiple                  640       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  multiple                 256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           multiple                  73856     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  multiple                 512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           multiple                  147584    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  multiple                 512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           multiple                  147584    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  multiple                 512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  113339    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 484,799\n",
      "Trainable params: 483,901\n",
      "Non-trainable params: 898\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'cnn_1/batch_normalization_5/FusedBatchNormV3' defined at (most recent call last):\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_13288\\707974291.py\", line 5, in <module>\n      vgg_model_history = vgg_model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[early_stopping,reduce_lr])\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_13288\\2131502132.py\", line 47, in call\n      x = self.mp_1(ELU()(self.bn_1(self.conv_1(x))))\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'cnn_1/batch_normalization_5/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,64,128,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node cnn_1/batch_normalization_5/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_77170]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m vgg_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m vgg_model_history \u001b[38;5;241m=\u001b[39m \u001b[43mvgg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m loss, accuracy, rocauc, prauc, f1macro \u001b[38;5;241m=\u001b[39m vgg_model\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'cnn_1/batch_normalization_5/FusedBatchNormV3' defined at (most recent call last):\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_13288\\707974291.py\", line 5, in <module>\n      vgg_model_history = vgg_model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[early_stopping,reduce_lr])\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_13288\\2131502132.py\", line 47, in call\n      x = self.mp_1(ELU()(self.bn_1(self.conv_1(x))))\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'cnn_1/batch_normalization_5/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,64,128,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node cnn_1/batch_normalization_5/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_77170]"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "vgg_model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['accuracy', tf.keras.metrics.AUC(curve='ROC'),tf.metrics.AUC(curve='PR'),tfa.metrics.F1Score(num_classes=59, average='macro')])\n",
    "vgg_model.summary()\n",
    "# Train the model\n",
    "vgg_model_history = vgg_model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[early_stopping,reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, rocauc, prauc, f1macro = vgg_model.evaluate(test_generator)\n",
    "print(f'Validation loss: {loss:.4f}, Validation accuracy: {accuracy:.4f}')\n",
    "\n",
    "base_model.save(\"vgg_model.h5\")\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f26096-e4b9-478c-8b60-ee11411f9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.1\n",
    "\n",
    "# spectrogram_path = 'C:/Projects/Music_Tagging/processed_data/00_468500.low.npy'\n",
    "# spectrogram = np.load(spectrogram_path)  # Replace with the path to your spectrogram file\n",
    "# spectrogram = spectrogram.reshape(1, 128, 128, 1)  # Add a batch dimension\n",
    "\n",
    "# predictions = model.predict(spectrogram)\n",
    "\n",
    "# class_indices = np.where(predictions[0] >= threshold)[0]  # Use a threshold to select classes\n",
    "\n",
    "# # Get the class labels corresponding to the selected indices\n",
    "# selected_classes = [unique_classes[i] for i in class_indices]\n",
    "\n",
    "# # Print or use the selected classes\n",
    "# print(\"Selected classes:\", selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2ef0f-426e-44b7-9dc9-184433d38d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LSTM, Dense, Flatten, TimeDistributed, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_crnn_model(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv_1 = Conv2D(64, (3, 3), activation='relu')(input_layer)\n",
    "    pool_1 = MaxPooling2D((2, 2))(conv_1)\n",
    "    bn_1 = BatchNormalization()(pool_1)\n",
    "\n",
    "    conv_2 = Conv2D(128, (3, 3), activation='relu')(bn_1)\n",
    "    pool_2 = MaxPooling2D((2, 2))(conv_2)\n",
    "    bn_2 = BatchNormalization()(pool_2)\n",
    "\n",
    "    conv_3 = Conv2D(256, (3, 3), activation='relu')(bn_2)\n",
    "    pool_3 = MaxPooling2D((2, 2))(conv_3)\n",
    "    bn_3 = BatchNormalization()(pool_3)\n",
    "\n",
    "    conv_4 = Conv2D(256, (3, 3), activation='relu')(bn_3)\n",
    "    pool_4 = MaxPooling2D((2, 2))(conv_4)\n",
    "    bn_4 = BatchNormalization()(pool_4)\n",
    "    \n",
    "    # Reshape output for RNN input\n",
    "    reshape = TimeDistributed(Flatten())(bn_4)\n",
    "\n",
    "    # RNN layer\n",
    "    lstm = LSTM(128, return_sequences=False)(reshape)\n",
    "    lstm = LSTM(128, return_sequences=False)(reshape)\n",
    "    # Fully connected layer\n",
    "    dense = Dense(64, activation='relu')(lstm)\n",
    "    output_layer = Dense(num_classes, activation='sigmoid')(dense)  # sigmoid for multi-label classification\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Define your model\n",
    "input_shape = (128, 1024, 1)  # example input shape, adjust to your needs\n",
    "num_classes = 59  # adjust to the number of classes\n",
    "crnn_model = create_crnn_model(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414a879-3766-40d9-a6d3-735676bdae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "crnn_model.compile(optimizer=Adam(learning_rate=initial_learning_rate), loss=BinaryCrossentropy(), metrics=['accuracy', tf.keras.metrics.AUC(curve='ROC'),tf.metrics.AUC(curve='PR'),tfa.metrics.F1Score(num_classes=59, average='macro')])\n",
    "crnn_model.summary()\n",
    "# Train the model\n",
    "crnn_model_history = crnn_model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[early_stopping,reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, rocauc, prauc, f1macro = crnn_model.evaluate(test_generator)\n",
    "print(f'Validation loss: {loss:.4f}, Validation accuracy: {accuracy:.4f}')\n",
    "\n",
    "base_model.save(\"crnn_model.h5\")\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b318d84-746c-4ff3-be4a-3460601c46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram_path = 'C:/Projects/Music_Tagging/processed_data/00_387400.low.npy'\n",
    "# spectrogram = np.load(spectrogram_path)  # Replace with the path to your spectrogram file\n",
    "# spectrogram = spectrogram.reshape(1, 128, 128, 1)  # Add a batch dimension\n",
    "\n",
    "# predictions = model.predict(spectrogram)\n",
    "\n",
    "# # Define a threshold\n",
    "# threshold = 0.1  # Adjust based on your model and problem\n",
    "\n",
    "# # Apply threshold to prediction to get binary values\n",
    "# predicted_labels = (predictions > threshold).astype(int)\n",
    "\n",
    "# # Print or use the predicted labels\n",
    "# print(\"Predicted labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce971966-71e0-4909-8b67-afeaeaf33a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
